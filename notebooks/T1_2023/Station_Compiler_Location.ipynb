{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is used to extract data for latitude and longitude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOLLOW THE STEPS BELOW:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, it will prompt you to enter the file location. The file location can be a raw.githubusercontent.com or right click on the dataset and copy the file path, copy path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://raw.githubusercontent.com/Chameleon-company/EVCFLO/main/datasets/T1_2023/Electric%20Vehicle%20Charging%20Stations%20NSW%20-%2020211207/Electric%20Vehicle%20Charging%20Stations%20NSW%20-%2020211207.csv\"\n",
    "\n",
    "url=\"\"\n",
    "\n",
    "def load_data(url=None):\n",
    "    if url is None:\n",
    "        url = input(\"Please enter the URL to the CSV file: \")\n",
    "    \n",
    "    data = pd.read_csv(url)\n",
    "    return data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, It will tell you the number of rows and columns as well as the column names and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 28871 rows and 91 columns.\n",
      "Columns & data types in the dataset:\n",
      "name            object\n",
      "latitude       float64\n",
      "longitude      float64\n",
      "Unnamed: 3     float64\n",
      "Unnamed: 4     float64\n",
      "                ...   \n",
      "Unnamed: 86    float64\n",
      "Unnamed: 87    float64\n",
      "Unnamed: 88    float64\n",
      "Unnamed: 89    float64\n",
      "Unnamed: 90    float64\n",
      "Length: 91, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"This dataset has\", data.shape[0], \"rows and\", data.shape[1], \"columns.\")\n",
    "\n",
    "print(\"Columns & data types in the dataset:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, it will prompt you to enter the column for station name / location, latitude, and longitude. use the list above to pick the correct columns or open the CSV file and find the names for the right columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 28871 rows and 3 columns.\n",
      "Columns & data types in the dataset:\n",
      "Service_Station_Location     object\n",
      "Latitude                    float64\n",
      "Longitude                   float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "station = input(\"Enter the column name for Station_Location: \")\n",
    "latitude = input(\"Enter the column name for Latitude: \")\n",
    "longitude = input(\"Enter the column name for Longitude: \")\n",
    "\n",
    "new_df = pd.DataFrame(data, columns=[station, latitude, longitude])\n",
    "\n",
    "new_df = new_df.rename(columns={\n",
    "    station: \"Service_Station_Location\",\n",
    "    latitude: \"Latitude\",\n",
    "    longitude: \"Longitude\"\n",
    "})\n",
    "\n",
    "print(\"This dataset has\", new_df.shape[0], \"rows and\", new_df.shape[1], \"columns.\")\n",
    "\n",
    "print(\"Columns & data types in the dataset:\")\n",
    "print(new_df.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below can be used if you would like to create a new csv file to store the new data to, otherwise the code cell after will ask for the file you would like to add to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df.to_csv(\"Paste location including a file name for your new csv, example: file location/blank.csv\", index=False)\n",
    "\n",
    "#save_location = input(\"Enter the save location for the blank CSV file: \")\n",
    "\n",
    "#new_df.to_csv(save_location, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, It will prompt you to enter the file location of the CSV file that you would like to add the data to. This is the same process as the first code cell except we are picking the csv file that we want to add on to. It will add the data we collected using the pandas concat function, don't worry about accidently adding duplicates it will handle these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_df_location = input(\"Enter the file location for the CSV file: \")\n",
    "\n",
    "from_df = pd.read_csv(from_df_location)\n",
    "\n",
    "combined_df = pd.concat([from_df, new_df], ignore_index=True)\n",
    "\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Warning! Overwrite the existing dataset with the combined dataset\n",
    "combined_df.to_csv(from_df_location, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below, We can now check to see the shape of the dataset that we have added more data to. Here we can track the number of station locations indicated by the number of rows! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 88316 rows and 3 columns.\n",
      "Columns & data types in the dataset:\n",
      "Service_Station_Location     object\n",
      "Latitude                    float64\n",
      "Longitude                   float64\n",
      "dtype: object\n",
      "                            Service_Station_Location   Latitude   Longitude\n",
      "0  9 Murray Rose,SYDNEY OLYMPIC PARK NSW 2127,AUS... -33.845898  151.069768\n",
      "1           76 Cowper St,WALLSEND NSW 2287,AUSTRALIA -32.902780  151.669841\n",
      "2  Hunter Valley Gardens 2090 Broke Road,POKOLBIN... -32.773929  151.293163\n",
      "3  Cnr Hume Highway & Bessemer Street,MITTAGONG N... -34.449540  150.442926\n",
      "4              140 Queen St,BERRY NSW 2535,AUSTRALIA -34.775939  150.700542\n"
     ]
    }
   ],
   "source": [
    "print(\"This dataset has\", combined_df.shape[0], \"rows and\", combined_df.shape[1], \"columns.\")\n",
    "\n",
    "print(\"Columns & data types in the dataset:\")\n",
    "print(combined_df.dtypes)\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
